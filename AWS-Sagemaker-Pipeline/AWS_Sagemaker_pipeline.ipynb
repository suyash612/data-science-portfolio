{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ed4378d-47f2-4bd0-a003-036230d4851a",
   "metadata": {},
   "source": [
    "# AWS Sagemaker pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c324d9a-fb25-4f5a-b053-f0bb0da9d501",
   "metadata": {},
   "source": [
    "1. Imports \n",
    "2. Configuration \n",
    "3. Data <br>",
    "&emsp;3.1 Train data <br>\n",
    "&emsp;3.2 Batch inference data <br>\n",
    "4. Pipeline components <br>\n",
    "4.1 Define Parameters of pipeline <br>\n",
    "4.2 Feature Engineering Processing step <br>\n",
    "4.2.1 Code for preprocessing <br>\n",
    "4.2.2 SKLearn Processor instance <br>\n",
    "4.2.3 Sagemaker pipeline - Processing Step <br>\n",
    "4.3 Training step <br>\n",
    "4.3.1 Sagemaker XGboost <br>\n",
    "4.3.2 Sagemaker pipeline - Training step <br>\n",
    "4.4 Model evaluation Processing step <br>\n",
    "4.4.1 Code for model validation<br>\n",
    "4.4.2 Script processor instance<br>\n",
    "4.4.3 Sagemaker pipeline - Processing Step<br>\n",
    "4.5 Batch inference<br>\n",
    "4.5.1 Success - Conditional step<br>\n",
    "4.5.2 Fail - Conditional step<br>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ff8e8a-f5e0-44ab-a7e4-4e90c6f031c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "44ae9a0a-b2d4-4b78-bbf7-0e90f444bc81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput, ScriptProcessor\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput, CreateModelInput, TransformInput\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d644a570-934c-4fd1-94ca-23e147dc026d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Sagemaker pipeline workflow imports\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    "    ParameterFloat,\n",
    ")\n",
    "from sagemaker.workflow.steps import ProcessingStep, TrainingStep, TransformStep\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.workflow.fail_step import FailStep\n",
    "from sagemaker.workflow.functions import Join\n",
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "from sagemaker.workflow.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c409ec5e-63d4-4fab-bb8c-b2da97386bae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker>=2.99.0 in /opt/conda/lib/python3.7/site-packages (2.116.0)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.7/site-packages (from sagemaker>=2.99.0) (0.1.5)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker>=2.99.0) (3.20.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker>=2.99.0) (20.1)\n",
      "Requirement already satisfied: boto3<2.0,>=1.20.21 in /opt/conda/lib/python3.7/site-packages (from sagemaker>=2.99.0) (1.26.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from sagemaker>=2.99.0) (1.3.5)\n",
      "Requirement already satisfied: attrs<23,>=20.3.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker>=2.99.0) (22.1.0)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.7/site-packages (from sagemaker>=2.99.0) (0.2.0)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker>=2.99.0) (1.0.1)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.7/site-packages (from sagemaker>=2.99.0) (0.3.0)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.7/site-packages (from sagemaker>=2.99.0) (0.7.5)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker>=2.99.0) (4.13.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker>=2.99.0) (1.21.6)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.20.21->sagemaker>=2.99.0) (0.6.0)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.8 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.20.21->sagemaker>=2.99.0) (1.29.8)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.20.21->sagemaker>=2.99.0) (1.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker>=2.99.0) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker>=2.99.0) (3.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker>=2.99.0) (2.4.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker>=2.99.0) (1.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->sagemaker>=2.99.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->sagemaker>=2.99.0) (2019.3)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker>=2.99.0) (1.7.6.6)\n",
      "Requirement already satisfied: dill>=0.3.6 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker>=2.99.0) (0.3.6)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker>=2.99.0) (0.70.14)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker>=2.99.0) (0.3.2)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.7/site-packages (from schema->sagemaker>=2.99.0) (0.6.0.post1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.30.0,>=1.29.8->boto3<2.0,>=1.20.21->sagemaker>=2.99.0) (1.26.12)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install \"sagemaker>=2.99.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f729ec9-326f-4a85-a16a-a9766393d854",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Configuration settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a930f20c-faff-467a-a5a2-88b0f1546f77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.session.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "pipeline_session = PipelineSession()\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "model_package_group_name = f\"AbaloneModelPackageGroupName\"#Model registry name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c550982c-4972-499f-8335-7663865f5f9d",
   "metadata": {},
   "source": [
    "# 3. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167eb2ae-c21a-4862-bdf1-2f3c0053db35",
   "metadata": {},
   "source": [
    "## 3.1 Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "080b29e9-8f97-41bc-bf63-b2396cf9cb6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5799f980-ff18-4f50-9fd2-91cfbc963688",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download data\n",
    "local_path = \"data/abalone-dataset.csv\"\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3.Bucket(f\"sagemaker-sample-files\").download_file(\n",
    "    \"datasets/tabular/uci_abalone/abalone.csv\", local_path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "982bb02a-96c4-4fb9-91d8-f33afa6aec06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-northeast-1-604458403141/abalone/abalone-dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Upload data to S3\n",
    "base_uri = f\"s3://{default_bucket}/abalone\"\n",
    "input_data_uri = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=local_path,\n",
    "    desired_s3_uri=base_uri,\n",
    ")\n",
    "print(input_data_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f7ebfa-8b07-4e00-b5a1-e5d9af36e693",
   "metadata": {},
   "source": [
    "## 3.2 Batch inference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6ade917-f9a1-46de-82a2-3f6740b30da8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download data\n",
    "local_path = \"data/abalone-dataset-batch\"\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3.Bucket(f\"sagemaker-servicecatalog-seedcode-{region}\").download_file(\n",
    "    \"dataset/abalone-dataset-batch\", local_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "581b1e4d-42fa-4c5e-96aa-26fb68bf1796",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-northeast-1-604458403141/abalone/abalone-dataset-batch\n"
     ]
    }
   ],
   "source": [
    "# upload data\n",
    "base_uri = f\"s3://{default_bucket}/abalone\"\n",
    "batch_data_uri = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=local_path,\n",
    "    desired_s3_uri=base_uri,\n",
    ")\n",
    "print(batch_data_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef6f5c9-1ac1-4008-9793-e314fdba1129",
   "metadata": {},
   "source": [
    "# 4. PIPELINE COMPONENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205090f9-1c01-450d-8193-af68521973bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4.1 Define Parameters of pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bffbc33e-5a35-4e7b-8c67-87510ef04d1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Number of compute instances\n",
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=1)\n",
    "\n",
    "# Type of instances\n",
    "instance_type = ParameterString(name=\"TrainingInstanceType\", default_value=\"ml.m5.xlarge\")\n",
    "\n",
    "# Default approval state of the model \n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\", default_value=\"PendingManualApproval\"\n",
    ")\n",
    "\n",
    "# Path of the train data\n",
    "input_data = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=input_data_uri,\n",
    ")\n",
    "\n",
    "# Path of the batch prediction data\n",
    "batch_data = ParameterString(\n",
    "    name=\"BatchData\",\n",
    "    default_value=batch_data_uri,\n",
    ")\n",
    "\n",
    "# Threshold amount\n",
    "mse_threshold = ParameterFloat(name=\"MseThreshold\", default_value=6.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bb2e25-7c46-4429-a9f2-955aa3ff40d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4.2 Feature Engineering Processing step\n",
    "\n",
    "- Fill in missing sex category data and encode it so that it is suitable for training.\n",
    "- Scale and normalize all numerical fields, aside from sex and rings numerical data.\n",
    "- Split the data into training, validation, and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0044a30-132c-4455-9535-51bc69cb3e31",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.2.1 Code for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "915b72a2-ccf4-47fb-9226-266e705926ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62172ac6-d09d-4caa-a23c-391484b244b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing code/preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/preprocessing.py\n",
    "import argparse\n",
    "import os\n",
    "import requests\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "\n",
    "# Since we get a headerless CSV file, we specify the column names here.\n",
    "feature_columns_names = [\n",
    "    \"sex\",\n",
    "    \"length\",\n",
    "    \"diameter\",\n",
    "    \"height\",\n",
    "    \"whole_weight\",\n",
    "    \"shucked_weight\",\n",
    "    \"viscera_weight\",\n",
    "    \"shell_weight\",\n",
    "]\n",
    "label_column = \"rings\"\n",
    "\n",
    "feature_columns_dtype = {\n",
    "    \"sex\": str,\n",
    "    \"length\": np.float64,\n",
    "    \"diameter\": np.float64,\n",
    "    \"height\": np.float64,\n",
    "    \"whole_weight\": np.float64,\n",
    "    \"shucked_weight\": np.float64,\n",
    "    \"viscera_weight\": np.float64,\n",
    "    \"shell_weight\": np.float64,\n",
    "}\n",
    "label_column_dtype = {\"rings\": np.float64}\n",
    "\n",
    "\n",
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_dir = \"/opt/ml/processing\"\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        f\"{base_dir}/input/abalone-dataset.csv\",\n",
    "        header=None,\n",
    "        names=feature_columns_names + [label_column],\n",
    "        dtype=merge_two_dicts(feature_columns_dtype, label_column_dtype), #read .csv from local\n",
    "    )\n",
    "    \n",
    "    #Define separate pipeline for numerice features - imputer + scaler\n",
    "    numeric_features = list(feature_columns_names)\n",
    "    numeric_features.remove(\"sex\")\n",
    "    numeric_transformer = Pipeline(\n",
    "        steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    "    ) \n",
    "\n",
    "    #Define separate pipeline for categorical features - imputer + one-hot encoding\n",
    "    categorical_features = [\"sex\"]\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ]\n",
    "    ) \n",
    "\n",
    "    #transform different column subset separately and concat features\n",
    "    preprocess = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_features),\n",
    "            (\"cat\", categorical_transformer, categorical_features),\n",
    "        ]\n",
    "    ) \n",
    "\n",
    "    #Preprocess data\n",
    "    y = df.pop(\"rings\")\n",
    "    X_pre = preprocess.fit_transform(df)\n",
    "    y_pre = y.to_numpy().reshape(len(y), 1)\n",
    "\n",
    "    X = np.concatenate((y_pre, X_pre), axis=1)\n",
    "\n",
    "    #train, validation, test split\n",
    "    np.random.shuffle(X)\n",
    "    train, validation, test = np.split(X, [int(0.7 * len(X)), int(0.85 * len(X))])\n",
    "\n",
    "    #Save data to local of container running this .py file\n",
    "    pd.DataFrame(train).to_csv(f\"{base_dir}/train/train.csv\", header=False, index=False)\n",
    "    pd.DataFrame(validation).to_csv(\n",
    "        f\"{base_dir}/validation/validation.csv\", header=False, index=False\n",
    "    )\n",
    "    pd.DataFrame(test).to_csv(f\"{base_dir}/test/test.csv\", header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bee067-89ea-48c3-ad0f-b7a7798aff29",
   "metadata": {},
   "source": [
    "### 4.2.2 SKLearn Processor instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52f4a100-17cb-4f3f-af02-a63585695d86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Defining sklearn processor docker container specifications\n",
    "framework_version = \"0.23-1\"\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"sklearn-abalone-process\",\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73f59bc-eb32-4320-8f54-61065c25dcd3",
   "metadata": {},
   "source": [
    "### 4.2.3 Sagemaker pipeline - Processing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36284386-2f7a-4819-8fa5-6a7d65ad3af2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/pipeline_context.py:261: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "#Run the docker container but this time it does not launch the processing job, \n",
    "#it returns the arguments needed to run the job as a step in the pipeline\n",
    "\n",
    "processor_args = sklearn_processor.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(source=input_data, destination=\"/opt/ml/processing/input\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n",
    "    ],\n",
    "    code=\"code/preprocessing.py\",\n",
    ")\n",
    "\n",
    "step_process = ProcessingStep(name=\"AbaloneProcess\", step_args=processor_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0db24c-ade5-400a-aa6c-e5c49df95cc3",
   "metadata": {},
   "source": [
    "## 4.3 Training step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eb739f-840a-4346-b479-e2df07f823c1",
   "metadata": {},
   "source": [
    "### 4.3.1 Sagemaker XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9692788-ec60-412c-a123-51f7ec740fca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = f\"s3://{default_bucket}/AbaloneTrain\"\n",
    "\n",
    "#Define the specs of XGB docker image\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.0-1\",\n",
    "    py_version=\"py3\",\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    ")\n",
    "\n",
    "#Run the XGB image in a container\n",
    "xgb_train = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=instance_type,\n",
    "    instance_count=1,\n",
    "    output_path=model_path,\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n",
    "xgb_train.set_hyperparameters(\n",
    "    objective=\"reg:linear\",\n",
    "    num_round=50,\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.7,\n",
    ")\n",
    "\n",
    "train_args = xgb_train.fit(\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ), #Using the output of the previous step \n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcb5422-6c3b-40b3-97a9-ca78c109feec",
   "metadata": {},
   "source": [
    "### 4.3.2 Sagemaker pipeline - Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5713aea3-9bb6-4dce-a223-d3135d8b9e45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "step_train = TrainingStep(\n",
    "    name=\"AbaloneTrain\",\n",
    "    step_args=train_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74880e0-efbf-4476-aeb1-e75e55cf16f9",
   "metadata": {},
   "source": [
    "## 4.4 Model evaluation Processing step\n",
    "\n",
    "- Load the model.\n",
    "- Read the test data.\n",
    "- Issue predictions against the test data.\n",
    "- Build a classification report, including accuracy and ROC curve.\n",
    "- Save the evaluation report to the evaluation directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d398b022-cf3e-4ed8-a62c-7ed038baed41",
   "metadata": {},
   "source": [
    "### 4.4.1 Code for model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7d00797-3eb3-427c-aea3-ea989ec50e3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing code/evaluation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/evaluation.py\n",
    "import json\n",
    "import pathlib\n",
    "import pickle\n",
    "import tarfile\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = f\"/opt/ml/processing/model/model.tar.gz\"\n",
    "    with tarfile.open(model_path) as tar:\n",
    "        tar.extractall(path=\".\")\n",
    "\n",
    "    model = pickle.load(open(\"xgboost-model\", \"rb\"))\n",
    "\n",
    "    test_path = \"/opt/ml/processing/test/test.csv\"\n",
    "    df = pd.read_csv(test_path, header=None)\n",
    "\n",
    "    y_test = df.iloc[:, 0].to_numpy()\n",
    "    df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "    X_test = xgboost.DMatrix(df.values)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    std = np.std(y_test - predictions)\n",
    "    report_dict = {\n",
    "        \"regression_metrics\": {\n",
    "            \"mse\": {\"value\": mse, \"standard_deviation\": std},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    output_dir = \"/opt/ml/processing/evaluation\"\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    evaluation_path = f\"{output_dir}/evaluation.json\"\n",
    "    with open(evaluation_path, \"w\") as f:\n",
    "        f.write(json.dumps(report_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1225907-42db-4b50-ab57-74a11e34a0bd",
   "metadata": {},
   "source": [
    "### 4.4.2 Script processor instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66582fbb-6e4b-4ae3-bee6-b03787dcb19d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "script_eval = ScriptProcessor(\n",
    "    image_uri=image_uri, #XGB image defined earlier\n",
    "    command=[\"python3\"],\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    base_job_name=\"script-abalone-eval\",\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n",
    "\n",
    "#Run the script processor image in a docker container\n",
    "eval_args = script_eval.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "    ],\n",
    "    code=\"code/evaluation.py\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d2584b-632f-46b8-942a-9b22bf050fd3",
   "metadata": {},
   "source": [
    "### 4.4.3 Sagemaker pipeline - Processing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c464c0c-b429-4a98-ab02-468edc793779",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4df4a5f4-c9d0-4b99-a60b-02e3d4340a47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "step_eval = ProcessingStep(\n",
    "    name=\"AbaloneEval\",\n",
    "    step_args=eval_args,\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd216dcd-56e8-4934-b812-06ae1df29028",
   "metadata": {},
   "source": [
    "## 4.5 Batch inference \n",
    "The trained model is used for batch inference if it satisfies the threshold metric value. This is the 1st part of the conditional statement where the model performance is greater than the threshold and it can be used for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a86d8bd-a42f-45c8-ab2b-b6e5d6ac2092",
   "metadata": {},
   "source": [
    "### 4.5.1 Success - Conditional step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5a4874-0c27-4753-acdc-ea76371a5986",
   "metadata": {},
   "source": [
    "#### Sagemaker pipeline - Create model step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "38a180b2-629e-4296-bd26-8da729b78c7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts, #Model params from the train step\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "step_create_model = ModelStep(\n",
    "    name=\"AbaloneCreateModel\",\n",
    "    step_args=model.create(instance_type=\"ml.m5.large\", accelerator_type=\"ml.eia1.medium\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837c9fce-9cdb-4a97-84a5-deda584f31f9",
   "metadata": {},
   "source": [
    "#### Sagemaker pipeline - Transform Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f75c534-c02b-4a6d-b558-1997937bf5cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define transformer instance image specifications\n",
    "transformer = Transformer(\n",
    "    model_name=step_create_model.properties.ModelName,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    output_path=f\"s3://{default_bucket}/AbaloneTransform\",\n",
    ")\n",
    "\n",
    "step_transform = TransformStep(\n",
    "    name=\"AbaloneTransform\", transformer=transformer, inputs=TransformInput(data=batch_data)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313a5a6e-1f19-48a4-9d5a-ae02ddbce827",
   "metadata": {},
   "source": [
    "#### Sagemaker pipeline - Register Model Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e33a91b0-2142-4291-8154-4949149225a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  script-abalone-eval-2022-12-11-10-11-10-286\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': <sagemaker.workflow.properties.Properties object at 0x7fee09206d90>, 'LocalPath': '/opt/ml/processing/model', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': <sagemaker.workflow.properties.Properties object at 0x7fee091f02d0>, 'LocalPath': '/opt/ml/processing/test', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-ap-northeast-1-604458403141/script-abalone-eval-2022-12-11-10-11-10-286/input/code/evaluation.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'evaluation', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-ap-northeast-1-604458403141/script-abalone-eval-2022-12-11-10-10-08-528/output/evaluation', 'LocalPath': '/opt/ml/processing/evaluation', 'S3UploadMode': 'EndOfJob'}}]\n"
     ]
    }
   ],
   "source": [
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource( #specify the evaluation metrics json\n",
    "        s3_uri=\"{}/evaluation.json\".format(\n",
    "            step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "\n",
    "register_args = model.register(\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.xlarge\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics,\n",
    ")\n",
    "step_register = ModelStep(name=\"AbaloneRegisterModel\", step_args=register_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bb2a26-0e2d-40fd-bfef-91e98894daf5",
   "metadata": {},
   "source": [
    "### 4.5.2 Fail - Conditional step\n",
    "Fail Step to Terminate the Pipeline Execution and Mark it as Failed\n",
    "\n",
    "- Define a FailStep with customized error message, which indicates the cause of the execution failure.\n",
    "- Enter the FailStep error message with a Join function, which appends a static text string with the dynamic mse_threshold parameter to build a more informative error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a45aaaca-6a4c-409b-ba15-19bf2a985320",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "step_fail = FailStep(\n",
    "    name=\"AbaloneMSEFail\",\n",
    "    error_message=Join(on=\" \", values=[\"Execution failed due to MSE >\", mse_threshold]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1387979a-15e4-4079-b2bd-e63e5067687b",
   "metadata": {},
   "source": [
    "## 4.6 Define a Condition Step\n",
    "Define a Condition Step to Check Accuracy and Conditionally Create a Model and Run a Batch Transformation and Register a Model in the Model Registry, Or Terminate the Execution in Failed State\n",
    "A ConditionStep enables pipelines to support conditional execution in the pipeline DAG based on the conditions of the step properties\n",
    "\n",
    "- Define a ConditionLessThanOrEqualTo on the accuracy value found in the output of the evaluation step, step_eval.\n",
    "- Use the condition in the list of conditions in a ConditionStep.\n",
    "- Pass the CreateModelStep and TransformStep steps, and the RegisterModel step collection into the if_steps of the ConditionStep, which are only executed if the condition evaluates to True.\n",
    "- Pass the FailStep step into the else_steps of the ConditionStep, which is only executed if the condition evaluates to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f3ef13-8835-4759-8cc0-333b17b52d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_lte = ConditionLessThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"regression_metrics.mse.value\",\n",
    "    ),\n",
    "    right=mse_threshold,\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name=\"AbaloneMSECond\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_register, step_create_model, step_transform],\n",
    "    else_steps=[step_fail],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5293a760-1132-43d6-9886-3d0487fc1610",
   "metadata": {},
   "source": [
    "# 5. BUILD THE PIPELINE\n",
    "Combine the steps into a Pipeline so it can be executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81300473-9705-4662-a7cb-d836dc38d241",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = f\"AbalonePipeline\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_count,\n",
    "        instance_type,\n",
    "        model_approval_status,\n",
    "        input_data,\n",
    "        batch_data,\n",
    "        mse_threshold,\n",
    "    ],\n",
    "    steps=[step_process, step_train, step_eval, step_cond],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431c27a0-e6f8-463d-8ee4-388b7dcaf9e7",
   "metadata": {},
   "source": [
    "# 6. Submit the pipeline to SageMaker and start execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bda269-9f54-4884-a445-db431dd81322",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)\n",
    "execution = pipeline.start()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-1:102112518831:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
